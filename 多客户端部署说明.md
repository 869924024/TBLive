# 多客户端部署说明

## 📋 概述

本系统支持**多台电脑同时刷量，自动防止资源冲突**。所有 Cookie 和设备参数集中存储在远程 MySQL 数据库，各客户端实时申请和释放资源。

---

## 🏗️ 架构设计

```
┌─────────────────────────────────────────────────────┐
│              远程MySQL数据库（中心化存储）              │
│  - tb_cookies（Cookie池，支持锁定+冷却）               │
│  - tb_devices（设备池，支持锁定+冷却）                 │
│  - tb_clients（客户端管理）                           │
└─────────────────────────────────────────────────────┘
                          ↑
          ┌───────────────┼───────────────┐
          │               │               │
    ┌─────▼─────┐   ┌─────▼─────┐   ┌─────▼─────┐
    │  电脑A     │   │  电脑B     │   │  电脑C     │
    │ (客户端1)  │   │ (客户端2)  │   │ (客户端3)  │
    └───────────┘   └───────────┘   └───────────┘

时序流程：
1. 任务开始前 → 申请资源（锁定）
2. 任务执行中 → 使用本地缓存（不访问数据库）
3. 任务结束后 → 释放资源（标记12小时冷却）
```

### ✅ 核心特性

1. **实时分配**：任务前从服务器申请可用资源
2. **原子锁定**：使用数据库事务防止并发冲突
3. **自动冷却**：使用后进入 12 小时冷却期
4. **零影响刷量**：任务执行期间完全不操作数据库

---

## 📦 部署步骤

### 第一步：准备远程 MySQL 数据库

1. **购买云服务器**（或使用现有服务器）

   - 阿里云、腾讯云、华为云等
   - 最低配置：1 核 2G 即可

2. **安装 MySQL 5.7+**

   ```bash
   # CentOS/RHEL
   sudo yum install mysql-server

   # Ubuntu/Debian
   sudo apt install mysql-server
   ```

3. **创建数据库和用户**

   ```sql
   CREATE DATABASE tb_live CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
   CREATE USER 'tb_live'@'%' IDENTIFIED BY '你的密码';
   GRANT ALL PRIVILEGES ON tb_live.* TO 'tb_live'@'%';
   FLUSH PRIVILEGES;
   ```

4. **导入数据库结构**

   ```bash
   mysql -u tb_live -p tb_live < database_schema.sql
   ```

5. **如果是升级现有数据库，执行迁移脚本**
   ```bash
   mysql -u tb_live -p tb_live < migrate_database.sql
   ```

---

### 第二步：启动 API 服务器

1. **修改配置**

   编辑 `api_server.py`，修改数据库配置：

   ```python
   DB_CONFIG = {
       'host': '你的服务器IP',
       'port': 3306,
       'user': 'tb_live',
       'password': '你的数据库密码',
       'database': 'tb_live',
       'charset': 'utf8mb4'
   }
   ```

2. **安装依赖**

   ```bash
   pip install flask pymysql
   ```

3. **启动服务**

   ```bash
   python api_server.py
   ```

   服务将监听在 `0.0.0.0:5000`

4. **（推荐）使用进程守护工具**
   ```bash
   # 使用 supervisor 或 systemd 保持服务运行
   # 或使用 screen/tmux
   screen -S api_server
   python api_server.py
   # Ctrl+A+D 分离
   ```

---

### 第三步：导入 Cookie 和设备参数

1. **准备数据文件**

   - `账号.txt`：每行一个 Cookie
   - `设备.txt`：每行一个设备（Tab 分隔的 5 个字段）

2. **运行导入工具**

   ```bash
   python import_data_to_db.py
   ```

3. **按提示操作**

   ```
   请选择操作:
   1. 导入Cookie (账号.txt)
   2. 导入设备 (设备.txt)
   3. 导入全部 (账号.txt + 设备.txt)
   4. 查看数据统计
   5. 分配数据给客户端
   ```

4. **分配资源给客户端**

   示例：给客户端 1 分配 100 个 Cookie 和 500 个设备

   ```
   选择: 5
   客户端ID: 1
   分配Cookie数量: 100
   分配设备数量: 500
   ```

---

### 第四步：配置各台电脑的客户端

在每台电脑上：

1. **安装客户端**

   ```bash
   pip install -r requirements.txt
   ```

2. **启动客户端**

   ```bash
   python ui_client.py
   ```

3. **配置客户端**

   进入"配置管理"页面：

   - **API 地址**：`http://你的服务器IP:5000`
   - **客户端密钥**：
     - 电脑 1: `client_key_001`
     - 电脑 2: `client_key_002`
     - 电脑 3: `client_key_003`
     - ...以此类推

   点击"保存"

4. **不需要手动导入 Cookie/设备**

   ⚠️ **重要**：新版本不再需要手动导入数据到本地！

   客户端会在任务开始时自动从服务器申请资源。

---

## 🚀 使用流程

### 单次任务流程

```
1. 打开客户端 → 配置管理页面 → 确认API配置正确

2. 刷量操作页面 → 输入直播间ID

3. 点击"开始刷量"
   ↓
   【自动】从服务器申请1个Cookie + N个设备
   ↓
   【自动】锁定这些资源（其他客户端无法获取）
   ↓
   【执行】刷量任务（使用本地缓存，不访问数据库）
   ↓
   【自动】任务完成后释放资源，标记12小时冷却
   ↓
   【自动】其他客户端可见冷却状态，不会重复使用

4. 完成！查看增量统计
```

### 多台电脑同时运行

✅ **完全支持**，无需担心冲突！

示例场景：

- 电脑 A：正在刷直播间 123456（使用 Cookie#1 + 设备#1-50）
- 电脑 B：同时刷直播间 789012（自动分配 Cookie#2 + 设备#51-100）
- 电脑 C：同时刷直播间 345678（自动分配 Cookie#3 + 设备#101-150）

系统自动保证：

- 不会分配相同的 Cookie
- 不会分配相同的设备
- 不会分配冷却中的资源

---

## 🔧 管理和维护

### 查看资源状态

```bash
python import_data_to_db.py
# 选择: 4. 查看数据统计
```

输出示例：

```
📊 数据库统计
🍪 Cookie总数: 500
   - 未分配: 100 个
   - 已分配: 400 个
📱 设备总数: 5000
   - 未分配: 1000 个
   - 已分配: 4000 个

📊 客户端数据分配:
客户端名称         密钥                  Cookie     设备
------------------------------------------------------------
电脑1            client_key_001       100        500
电脑2            client_key_002       100        500
电脑3            client_key_003       100        500
```

### 添加更多 Cookie/设备

随时可以导入新数据：

```bash
python import_data_to_db.py
# 选择: 3. 导入全部
# 选择: 5. 分配数据给客户端
```

### 清理过期锁（可选）

如果客户端异常退出导致资源一直锁定，可以手动解锁：

```sql
-- 清理超过1小时的锁
UPDATE tb_cookies
SET is_locked = 0, locked_by_client = NULL, locked_at = NULL
WHERE is_locked = 1 AND locked_at < DATE_SUB(NOW(), INTERVAL 1 HOUR);

UPDATE tb_devices
SET is_locked = 0, locked_by_client = NULL, locked_at = NULL
WHERE is_locked = 1 AND locked_at < DATE_SUB(NOW(), INTERVAL 1 HOUR);
```

### 调整冷却时间

默认 12 小时，可在客户端任务结束后修改：

```python
# ui_client.py 第781行
'cooldown_hours': 12  # 改为你想要的小时数
```

---

## ❓ 常见问题

### Q1: 提示"没有可用的 Cookie/设备"？

**原因**：所有资源都在冷却中或被锁定

**解决**：

1. 等待冷却结束（12 小时）
2. 或导入更多 Cookie/设备
3. 或减少冷却时间

### Q2: 多台电脑会冲突吗？

**不会**！系统使用数据库事务锁保证原子性，绝对不会分配重复资源。

### Q3: 客户端异常退出，资源会一直锁定吗？

正常情况下，任务结束会自动解锁。如果异常退出：

- 锁会在 1 小时后自动失效（可手动清理）
- 或重启 API 服务器

### Q4: 可以添加更多客户端吗？

可以！在数据库中插入新客户端：

```sql
INSERT INTO tb_clients (client_key, client_name, is_active)
VALUES ('client_key_011', '电脑11', 1);
```

然后分配资源即可。

### Q5: API 服务器挂了怎么办？

- 正在执行的任务不受影响（使用本地缓存）
- 但无法开始新任务（无法申请资源）
- 重启 API 服务器即可恢复

---

## 📈 性能优化建议

1. **数据库连接池**：生产环境建议使用连接池
2. **Redis 缓存**：高并发时可加 Redis 缓存热数据
3. **负载均衡**：多台 API 服务器 + Nginx 负载均衡
4. **监控告警**：监控资源使用率，及时补充

---

## 🎯 总结

✅ **优势**：

- 多台电脑并发运行，互不冲突
- 自动防止资源重复使用
- 自动管理冷却时间
- 刷量逻辑零影响

✅ **注意事项**：

- 确保 API 服务器稳定运行
- 定期备份数据库
- 合理分配资源给各客户端
- 根据实际情况调整冷却时间

✅ **扩展性**：

- 支持任意数量客户端
- 支持动态添加资源
- 支持实时监控统计

有任何问题欢迎反馈！🚀
